{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNochNvqkXOun68tGz0EvDW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shudh1999/CANCER/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/Shudh1999/CANCER.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHUZDKTS_lRy",
        "outputId": "a4872f82-d059-4b43-eaba-2e7d6ed0d01f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CANCER' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_WdFMi88rl2",
        "outputId": "3ab5c91b-3958-4f8b-b816-aa74e5a8aaae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/CANCER/braintumordataset.zip\n",
            "replace brain_tumor_dataset/no/1 no.jpeg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "  inflating: brain_tumor_dataset/no/10 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/11 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/12 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/13 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/14 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/15 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/17 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/18 no.jpg  \n",
            "replace brain_tumor_dataset/no/19 no.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace brain_tumor_dataset/no/2 no.jpeg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "  inflating: brain_tumor_dataset/no/20 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/21 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/22 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/23 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/24 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/25 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/26 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/27 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/28 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/29 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/3 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/30 no.jpg  \n",
            "replace brain_tumor_dataset/no/31 no.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "  inflating: brain_tumor_dataset/no/32 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/33 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/34 no.jpg  \n",
            "replace brain_tumor_dataset/no/35 no.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: brain_tumor_dataset/no/35 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/36 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/37 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/38 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/39 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/4 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/40 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/41 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/42 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/43 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/44no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/45 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/46 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/47 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/48 no.jpeg  \n",
            "  inflating: brain_tumor_dataset/no/49 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/5 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/50 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/6 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/7 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/8 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/9 no.jpg  \n",
            "  inflating: brain_tumor_dataset/no/N1.JPG  \n",
            "  inflating: brain_tumor_dataset/no/N11.jpg  \n",
            "  inflating: brain_tumor_dataset/no/N15.jpg  \n",
            "  inflating: brain_tumor_dataset/no/N16.jpg  \n",
            "  inflating: brain_tumor_dataset/no/N17.jpg  \n",
            "  inflating: brain_tumor_dataset/no/N19.JPG  \n",
            "  inflating: brain_tumor_dataset/no/N2.JPG  \n",
            "  inflating: brain_tumor_dataset/no/N20.JPG  \n",
            "  inflating: brain_tumor_dataset/no/N21.jpg  \n",
            "  inflating: brain_tumor_dataset/no/N22.JPG  \n",
            "  inflating: brain_tumor_dataset/no/N26.JPG  \n",
            "  inflating: brain_tumor_dataset/no/N3.jpg  \n",
            "  inflating: brain_tumor_dataset/no/N5.jpg  \n",
            "  inflating: brain_tumor_dataset/no/N6.jpg  \n",
            "  inflating: brain_tumor_dataset/no/No11.jpg  \n",
            "  inflating: brain_tumor_dataset/no/No12.jpg  \n",
            "  inflating: brain_tumor_dataset/no/No13.jpg  \n",
            "  inflating: brain_tumor_dataset/no/No14.jpg  \n",
            "  inflating: brain_tumor_dataset/no/No15.jpg  \n",
            "  inflating: brain_tumor_dataset/no/No16.jpg  \n",
            "  inflating: brain_tumor_dataset/no/No17.jpg  \n",
            "  inflating: brain_tumor_dataset/no/No18.jpg  \n",
            "  inflating: brain_tumor_dataset/no/No19.jpg  \n",
            "  inflating: brain_tumor_dataset/no/No20.jpg  \n",
            "  inflating: brain_tumor_dataset/no/No21.jpg  \n",
            "  inflating: brain_tumor_dataset/no/No22.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 1.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 10.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 100.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 2.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 3.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 4.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 5.jpeg  \n",
            "  inflating: brain_tumor_dataset/no/no 6.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 7.jpeg  \n",
            "  inflating: brain_tumor_dataset/no/no 8.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 89.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 9.png  \n",
            "  inflating: brain_tumor_dataset/no/no 90.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 91.jpeg  \n",
            "  inflating: brain_tumor_dataset/no/no 92.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 923.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 94.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 95.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 96.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 97.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 98.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no 99.jpg  \n",
            "  inflating: brain_tumor_dataset/no/no.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y1.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y10.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y100.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y101.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y102.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y103.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y104.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y105.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y106.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y107.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y108.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y109.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y11.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y111.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y112.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y113.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y114.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y115.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y116.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y117.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y12.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y120.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y13.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y14.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y146.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y147.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y148.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y15.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y153.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y154.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y155.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y156.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y157.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y158.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y159.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y16.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y160.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y161.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y162.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y163.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y164.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y165.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y166.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y167.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y168.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y169.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y17.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y170.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y18.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y180.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y181.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y182.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y183.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y184.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y185.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y186.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y187.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y188.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y19.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y192.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y193.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y194.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y195.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y2.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y20.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y21.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y22.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y23.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y24.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y242.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y243.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y244.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y245.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y246.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y247.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y248.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y249.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y25.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y250.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y251.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y252.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y253.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y254.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y255.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y256.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y257.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y258.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y259.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y26.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y27.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y28.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y29.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y3.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y30.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y31.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y32.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y33.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y34.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y35.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y36.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y37.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y38.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y39.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y4.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y40.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y41.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y42.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y44.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y45.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y46.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y47.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y49.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y50.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y51.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y52.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y53.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y54.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y55.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y56.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y58.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y59.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y6.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y60.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y61.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y62.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y65.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y66.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y67.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y69.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y7.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y70.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y71.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y73.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y74.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y75.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y76.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y77.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y78.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y79.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y8.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y81.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y82.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y85.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y86.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y89.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y9.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y90.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y91.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y92.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y92.png  \n",
            "  inflating: brain_tumor_dataset/yes/Y95.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y96.jpg  \n",
            "  inflating: brain_tumor_dataset/yes/Y97.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y98.JPG  \n",
            "  inflating: brain_tumor_dataset/yes/Y99.JPG  \n",
            "  inflating: no/1 no.jpeg            \n",
            "  inflating: no/10 no.jpg            \n",
            "  inflating: no/11 no.jpg            \n",
            "  inflating: no/12 no.jpg            \n",
            "  inflating: no/13 no.jpg            \n",
            "  inflating: no/14 no.jpg            \n",
            "  inflating: no/15 no.jpg            \n",
            "  inflating: no/17 no.jpg            \n",
            "  inflating: no/18 no.jpg            \n",
            "  inflating: no/19 no.jpg            \n",
            "  inflating: no/2 no.jpeg            \n",
            "  inflating: no/20 no.jpg            \n",
            "  inflating: no/21 no.jpg            \n",
            "  inflating: no/22 no.jpg            \n",
            "  inflating: no/23 no.jpg            \n",
            "  inflating: no/24 no.jpg            \n",
            "  inflating: no/25 no.jpg            \n",
            "  inflating: no/26 no.jpg            \n",
            "  inflating: no/27 no.jpg            \n",
            "  inflating: no/28 no.jpg            \n",
            "  inflating: no/29 no.jpg            \n",
            "  inflating: no/3 no.jpg             \n",
            "  inflating: no/30 no.jpg            \n",
            "  inflating: no/31 no.jpg            \n",
            "  inflating: no/32 no.jpg            \n",
            "  inflating: no/33 no.jpg            \n",
            "  inflating: no/34 no.jpg            \n",
            "  inflating: no/35 no.jpg            \n",
            "  inflating: no/36 no.jpg            \n",
            "  inflating: no/37 no.jpg            \n",
            "  inflating: no/38 no.jpg            \n",
            "  inflating: no/39 no.jpg            \n",
            "  inflating: no/4 no.jpg             \n",
            "  inflating: no/40 no.jpg            \n",
            "  inflating: no/41 no.jpg            \n",
            "  inflating: no/42 no.jpg            \n",
            "  inflating: no/43 no.jpg            \n",
            "  inflating: no/44no.jpg             \n",
            "  inflating: no/45 no.jpg            \n",
            "  inflating: no/46 no.jpg            \n",
            "  inflating: no/47 no.jpg            \n",
            "  inflating: no/48 no.jpeg           \n",
            "  inflating: no/49 no.jpg            \n",
            "  inflating: no/5 no.jpg             \n",
            "  inflating: no/50 no.jpg            \n",
            "  inflating: no/6 no.jpg             \n",
            "  inflating: no/7 no.jpg             \n",
            "  inflating: no/8 no.jpg             \n",
            "  inflating: no/9 no.jpg             \n",
            "  inflating: no/N1.JPG               \n",
            "  inflating: no/N11.jpg              \n",
            "  inflating: no/N15.jpg              \n",
            "  inflating: no/N16.jpg              \n",
            "  inflating: no/N17.jpg              \n",
            "  inflating: no/N19.JPG              \n",
            "  inflating: no/N2.JPG               \n",
            "  inflating: no/N20.JPG              \n",
            "  inflating: no/N21.jpg              \n",
            "  inflating: no/N22.JPG              \n",
            "  inflating: no/N26.JPG              \n",
            "  inflating: no/N3.jpg               \n",
            "  inflating: no/N5.jpg               \n",
            "  inflating: no/N6.jpg               \n",
            "  inflating: no/No11.jpg             \n",
            "  inflating: no/No12.jpg             \n",
            "  inflating: no/No13.jpg             \n",
            "  inflating: no/No14.jpg             \n",
            "  inflating: no/No15.jpg             \n",
            "  inflating: no/No16.jpg             \n",
            "  inflating: no/No17.jpg             \n",
            "  inflating: no/No18.jpg             \n",
            "  inflating: no/No19.jpg             \n",
            "  inflating: no/No20.jpg             \n",
            "  inflating: no/No21.jpg             \n",
            "  inflating: no/No22.jpg             \n",
            "  inflating: no/no 1.jpg             \n",
            "  inflating: no/no 10.jpg            \n",
            "  inflating: no/no 100.jpg           \n",
            "  inflating: no/no 2.jpg             \n",
            "  inflating: no/no 3.jpg             \n",
            "  inflating: no/no 4.jpg             \n",
            "  inflating: no/no 5.jpeg            \n",
            "  inflating: no/no 6.jpg             \n",
            "  inflating: no/no 7.jpeg            \n",
            "  inflating: no/no 8.jpg             \n",
            "  inflating: no/no 89.jpg            \n",
            "  inflating: no/no 9.png             \n",
            "  inflating: no/no 90.jpg            \n",
            "  inflating: no/no 91.jpeg           \n",
            "  inflating: no/no 92.jpg            \n",
            "  inflating: no/no 923.jpg           \n",
            "  inflating: no/no 94.jpg            \n",
            "  inflating: no/no 95.jpg            \n",
            "  inflating: no/no 96.jpg            \n",
            "  inflating: no/no 97.jpg            \n",
            "  inflating: no/no 98.jpg            \n",
            "  inflating: no/no 99.jpg            \n",
            "  inflating: no/no.jpg               \n",
            "  inflating: yes/Y1.jpg              \n",
            "  inflating: yes/Y10.jpg             \n",
            "  inflating: yes/Y100.JPG            \n",
            "  inflating: yes/Y101.jpg            \n",
            "  inflating: yes/Y102.jpg            \n",
            "  inflating: yes/Y103.jpg            \n",
            "  inflating: yes/Y104.jpg            \n",
            "  inflating: yes/Y105.jpg            \n",
            "  inflating: yes/Y106.jpg            \n",
            "  inflating: yes/Y107.jpg            \n",
            "  inflating: yes/Y108.jpg            \n",
            "  inflating: yes/Y109.JPG            \n",
            "  inflating: yes/Y11.jpg             \n",
            "  inflating: yes/Y111.JPG            \n",
            "  inflating: yes/Y112.JPG            \n",
            "  inflating: yes/Y113.JPG            \n",
            "  inflating: yes/Y114.JPG            \n",
            "  inflating: yes/Y115.JPG            \n",
            "  inflating: yes/Y116.JPG            \n",
            "  inflating: yes/Y117.JPG            \n",
            "  inflating: yes/Y12.jpg             \n",
            "  inflating: yes/Y120.JPG            \n",
            "  inflating: yes/Y13.jpg             \n",
            "  inflating: yes/Y14.jpg             \n",
            "  inflating: yes/Y146.JPG            \n",
            "  inflating: yes/Y147.JPG            \n",
            "  inflating: yes/Y148.JPG            \n",
            "  inflating: yes/Y15.jpg             \n",
            "  inflating: yes/Y153.jpg            \n",
            "  inflating: yes/Y154.jpg            \n",
            "  inflating: yes/Y155.JPG            \n",
            "  inflating: yes/Y156.JPG            \n",
            "  inflating: yes/Y157.JPG            \n",
            "  inflating: yes/Y158.JPG            \n",
            "  inflating: yes/Y159.JPG            \n",
            "  inflating: yes/Y16.JPG             \n",
            "  inflating: yes/Y160.JPG            \n",
            "  inflating: yes/Y161.JPG            \n",
            "  inflating: yes/Y162.jpg            \n",
            "  inflating: yes/Y163.JPG            \n",
            "  inflating: yes/Y164.JPG            \n",
            "  inflating: yes/Y165.JPG            \n",
            "  inflating: yes/Y166.JPG            \n",
            "  inflating: yes/Y167.JPG            \n",
            "  inflating: yes/Y168.jpg            \n",
            "  inflating: yes/Y169.jpg            \n",
            "  inflating: yes/Y17.jpg             \n",
            "  inflating: yes/Y170.JPG            \n",
            "  inflating: yes/Y18.JPG             \n",
            "  inflating: yes/Y180.jpg            \n",
            "  inflating: yes/Y181.jpg            \n",
            "  inflating: yes/Y182.JPG            \n",
            "  inflating: yes/Y183.jpg            \n",
            "  inflating: yes/Y184.JPG            \n",
            "  inflating: yes/Y185.jpg            \n",
            "  inflating: yes/Y186.jpg            \n",
            "  inflating: yes/Y187.jpg            \n",
            "  inflating: yes/Y188.jpg            \n",
            "  inflating: yes/Y19.JPG             \n",
            "  inflating: yes/Y192.JPG            \n",
            "  inflating: yes/Y193.JPG            \n",
            "  inflating: yes/Y194.jpg            \n",
            "  inflating: yes/Y195.JPG            \n",
            "  inflating: yes/Y2.jpg              \n",
            "  inflating: yes/Y20.jpg             \n",
            "  inflating: yes/Y21.jpg             \n",
            "  inflating: yes/Y22.jpg             \n",
            "  inflating: yes/Y23.JPG             \n",
            "  inflating: yes/Y24.jpg             \n",
            "  inflating: yes/Y242.JPG            \n",
            "  inflating: yes/Y243.JPG            \n",
            "  inflating: yes/Y244.JPG            \n",
            "  inflating: yes/Y245.jpg            \n",
            "  inflating: yes/Y246.JPG            \n",
            "  inflating: yes/Y247.JPG            \n",
            "  inflating: yes/Y248.JPG            \n",
            "  inflating: yes/Y249.JPG            \n",
            "  inflating: yes/Y25.jpg             \n",
            "  inflating: yes/Y250.jpg            \n",
            "  inflating: yes/Y251.JPG            \n",
            "  inflating: yes/Y252.jpg            \n",
            "  inflating: yes/Y253.JPG            \n",
            "  inflating: yes/Y254.jpg            \n",
            "  inflating: yes/Y255.JPG            \n",
            "  inflating: yes/Y256.JPG            \n",
            "  inflating: yes/Y257.jpg            \n",
            "  inflating: yes/Y258.JPG            \n",
            "  inflating: yes/Y259.JPG            \n",
            "  inflating: yes/Y26.jpg             \n",
            "  inflating: yes/Y27.jpg             \n",
            "  inflating: yes/Y28.jpg             \n",
            "  inflating: yes/Y29.jpg             \n",
            "  inflating: yes/Y3.jpg              \n",
            "  inflating: yes/Y30.jpg             \n",
            "  inflating: yes/Y31.jpg             \n",
            "  inflating: yes/Y32.jpg             \n",
            "  inflating: yes/Y33.jpg             \n",
            "  inflating: yes/Y34.jpg             \n",
            "  inflating: yes/Y35.jpg             \n",
            "  inflating: yes/Y36.JPG             \n",
            "  inflating: yes/Y37.jpg             \n",
            "  inflating: yes/Y38.jpg             \n",
            "  inflating: yes/Y39.jpg             \n",
            "  inflating: yes/Y4.jpg              \n",
            "  inflating: yes/Y40.JPG             \n",
            "  inflating: yes/Y41.jpg             \n",
            "  inflating: yes/Y42.jpg             \n",
            "  inflating: yes/Y44.JPG             \n",
            "  inflating: yes/Y45.JPG             \n",
            "  inflating: yes/Y46.jpg             \n",
            "  inflating: yes/Y47.JPG             \n",
            "  inflating: yes/Y49.JPG             \n",
            "  inflating: yes/Y50.JPG             \n",
            "  inflating: yes/Y51.jpg             \n",
            "  inflating: yes/Y52.jpg             \n",
            "  inflating: yes/Y53.jpg             \n",
            "  inflating: yes/Y54.jpg             \n",
            "  inflating: yes/Y55.jpg             \n",
            "  inflating: yes/Y56.jpg             \n",
            "  inflating: yes/Y58.JPG             \n",
            "  inflating: yes/Y59.JPG             \n",
            "  inflating: yes/Y6.jpg              \n",
            "  inflating: yes/Y60.jpg             \n",
            "  inflating: yes/Y61.jpg             \n",
            "  inflating: yes/Y62.jpg             \n",
            "  inflating: yes/Y65.JPG             \n",
            "  inflating: yes/Y66.JPG             \n",
            "  inflating: yes/Y67.JPG             \n",
            "  inflating: yes/Y69.jpg             \n",
            "  inflating: yes/Y7.jpg              \n",
            "  inflating: yes/Y70.jpg             \n",
            "  inflating: yes/Y71.JPG             \n",
            "  inflating: yes/Y73.jpg             \n",
            "  inflating: yes/Y74.jpg             \n",
            "  inflating: yes/Y75.JPG             \n",
            "  inflating: yes/Y76.jpg             \n",
            "  inflating: yes/Y77.jpg             \n",
            "  inflating: yes/Y78.jpg             \n",
            "  inflating: yes/Y79.jpg             \n",
            "  inflating: yes/Y8.jpg              \n",
            "  inflating: yes/Y81.jpg             \n",
            "  inflating: yes/Y82.jpg             \n",
            "  inflating: yes/Y85.JPG             \n",
            "  inflating: yes/Y86.JPG             \n",
            "  inflating: yes/Y89.JPG             \n",
            "  inflating: yes/Y9.jpg              \n",
            "  inflating: yes/Y90.jpg             \n",
            "  inflating: yes/Y91.jpg             \n",
            "  inflating: yes/Y92.jpg             \n",
            "  inflating: yes/Y92.png             \n",
            "  inflating: yes/Y95.jpg             \n",
            "  inflating: yes/Y96.jpg             \n",
            "  inflating: yes/Y97.JPG             \n",
            "  inflating: yes/Y98.JPG             \n",
            "  inflating: yes/Y99.JPG             \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/CANCER/braintumordataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import math\n",
        "import shutil\n",
        "import glob\n"
      ],
      "metadata": {
        "id": "kK1gOUxi8vOo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count the number of images in the respective classes 0 -\n",
        "ROOT_DIR = \"/content/brain_tumor_dataset\"\n",
        "number_of_images = {}\n",
        "\n",
        "for dir in os.listdir(ROOT_DIR):\n",
        "  number_of_images [dir] = len(os.listdir(os.path.join(ROOT_DIR, dir)))"
      ],
      "metadata": {
        "id": "WQC9gJle8v4x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_images.items()"
      ],
      "metadata": {
        "id": "n_xwuD_88y8v",
        "outputId": "15758c17-a817-4e59-bb5b-e3f8d1354fca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('no', 98), ('yes', 155)])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dataFolder(p, split):\n",
        "# we create a training folder\n",
        "  if not os.path.exists(\"./\"+p):\n",
        "    os.mkdir(\"./\"+p)\n",
        "    for dir in os.listdir(ROOT_DIR):\n",
        "      os.makedirs(\"./\"+p+\"/\"+dir)\n",
        "      for img in np.random.choice(a=os.listdir(os.path.join(ROOT_DIR, dir)),\n",
        "                                  size= (math.floor(split*number_of_images[dir])-5),\n",
        "                                  replace=False ):\n",
        "        O= os.path.join(ROOT_DIR, dir, img)\n",
        "        D = os.path.join(\"./\"+p,dir)\n",
        "        shutil.copy(O,D)\n",
        "        os.remove(O)\n",
        "  else:\n",
        "    print( f\"{p}Folder exsist\")"
      ],
      "metadata": {
        "id": "n6_E35Ji81i3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataFolder(\"train\", 0.7)"
      ],
      "metadata": {
        "id": "IjKf7qDx84G-",
        "outputId": "461b0e69-99c1-4afd-cff4-9addb4a43da5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainFolder exsist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataFolder(\"valid\", 0.15)"
      ],
      "metadata": {
        "id": "xeqvBxaQ864X",
        "outputId": "96e67d43-096e-48e2-d295-4d5bec6b7d11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validFolder exsist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataFolder(\"test\", 0.15)"
      ],
      "metadata": {
        "id": "d1TRacyE88YA",
        "outputId": "853c845c-40fa-48e8-ea88-c30d2c4fadf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testFolder exsist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating our model"
      ],
      "metadata": {
        "id": "fGWJlmDmCAya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense, BatchNormalization, GlobalAvgPool2D\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "qxFySJdJB-D7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model sequential\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters= 16, kernel_size= (3,3), activation= 'relu', input_shape = (224,224,3),padding='same'))\n",
        "\n",
        "model.add(Conv2D(filters=36, kernel_size= (3,3), activation= 'relu' ))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters= 64, kernel_size= (3,3), activation= 'relu' ))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters= 128, kernel_size= (3,3), activation= 'relu' ))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Dropout (rate= 0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=64, activation= 'relu'))\n",
        "model.add(Dropout (rate=0.25))\n",
        "model.add(Dense(units= 1, activation= 'sigmoid'))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "KMKztTdFCPQ2",
        "outputId": "3eb8a67a-cdac-4d0a-86b6-ba20cfda371b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 16)      448       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 222, 222, 36)      5220      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 111, 111, 36)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 109, 109, 64)      20800     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 52, 52, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 26, 26, 128)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 86528)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                5537856   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5638245 (21.51 MB)\n",
            "Trainable params: 5638245 (21.51 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss=keras.losses.binary_crossentropy,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3S9LdNrsD5oG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "prepaaring our data through data genrator"
      ],
      "metadata": {
        "id": "bRtPswHBEsRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessingImages1(path):\n",
        "\n",
        "  image_data = ImageDataGenerator( rescale=1/255, horizontal_flip= True)\n",
        "  image= image_data.flow_from_directory(directory=path, target_size = (224,224), batch_size = 32, class_mode = 'binary')\n",
        "  return image"
      ],
      "metadata": {
        "id": "uSegqsOlEzmD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path1= \"/content/train\"\n",
        "train_data=preprocessingImages1(path1)"
      ],
      "metadata": {
        "id": "oK2BWedhFebz",
        "outputId": "e4bfbdbc-73f1-44c8-dab1-d1c4f4d66ee9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 166 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessingImages2(path):\n",
        "\n",
        "  image_data = ImageDataGenerator(rescale=1/255)\n",
        "  image= image_data.flow_from_directory(directory=path, target_size = (224,224), batch_size = 32, class_mode = 'binary')\n",
        "  return image"
      ],
      "metadata": {
        "id": "5FW3CBzPGJu8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path2= \"/content/valid\"\n",
        "val_data=preprocessingImages2(path2)"
      ],
      "metadata": {
        "id": "x1qMcb9pF4Ex",
        "outputId": "63a977d6-50e8-4032-8914-3b0b6ddb35ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 27 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path3= \"/content/test\"\n",
        "test_data=preprocessingImages2(path3)"
      ],
      "metadata": {
        "id": "l9hAEaw1GZ_Q",
        "outputId": "ac09ce52-bbdb-4634-8923-6e5b27192513",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 27 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#early stoping condition dont want to waste the resources\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "# early stopping\n",
        "es=EarlyStopping(monitor=\"val_accuracy\", min_delta= 0.01, patience= 5, verbose=1, mode = 'auto')\n",
        "# model check point\n",
        "mc=ModelCheckpoint(monitor=\"val_accuracy\", filepath=\"./bestmodel.h5\", verbose=1, save_best_only= True, mode = 'auto')\n",
        "cd=[es,mc]"
      ],
      "metadata": {
        "id": "qwwRPgAfHWeQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model training"
      ],
      "metadata": {
        "id": "bNWNN6XMHsQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hs = model.fit(\n",
        "    x=train_data,  # Pass the generator directly as the `x` argument\n",
        "    epochs=30,\n",
        "    verbose=1,\n",
        "    validation_data=val_data,\n",
        "    steps_per_epoch=2,  # Specify steps_per_epoch\n",
        "    validation_steps=8,\n",
        "    callbacks=cd\n",
        ")\n"
      ],
      "metadata": {
        "id": "l7qHQrknHvmU",
        "outputId": "70736301-4fc6-4fb2-b003-13f81c63f883",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_accuracy improved from 0.85185 to 0.92593, saving model to ./bestmodel.h5\n",
            "2/2 [==============================] - 1s 682ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.0708 - val_accuracy: 0.9259\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9844"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 141ms/step - loss: 0.0221 - accuracy: 0.9844\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 3.6859e-04 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 198ms/step - loss: 3.6859e-04 - accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 154ms/step - loss: 0.0101 - accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 141ms/step - loss: 0.0095 - accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 5.9542e-04 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 141ms/step - loss: 5.9542e-04 - accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9844"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 138ms/step - loss: 0.0557 - accuracy: 0.9844\n",
            "Epoch 8/30\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 57ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 8.0211e-04 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 163ms/step - loss: 8.0211e-04 - accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9844"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 140ms/step - loss: 0.0593 - accuracy: 0.9844\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9844"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 150ms/step - loss: 0.0204 - accuracy: 0.9844\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 142ms/step - loss: 0.0139 - accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 59ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1322 - accuracy: 0.9688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 53ms/step - loss: 0.1114 - accuracy: 0.9737\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 4.9122e-04 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 218ms/step - loss: 4.9122e-04 - accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.3481e-04 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 52ms/step - loss: 2.0655e-04 - accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 223ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 141ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 142ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 143ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 215ms/step - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 155ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 153ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 1.0000    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 245ms/step - loss: 0.0144 - accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 207ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 1.0000    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 216ms/step - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 155ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 210ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 150ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 0s 149ms/step - loss: 0.0088 - accuracy: 1.0000\n"
          ]
        }
      ]
    }
  ]
}